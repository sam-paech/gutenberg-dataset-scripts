{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "import chardet\n",
    "import zipfile\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import re\n",
    "import openai\n",
    "\n",
    "# %%\n",
    "# Initialize the thread lock\n",
    "lock = threading.Lock()\n",
    "\n",
    "# %%\n",
    "# Configuration for Gemini\n",
    "gemini_model = None\n",
    "def run_gemini_query(prompt, history, completion_tokens, temp, model):\n",
    "    global gemini_model\n",
    "    try:\n",
    "        if not gemini_model:\n",
    "            genai.configure(api_key=\"\")            \n",
    "            gemini_model = genai.GenerativeModel(model)\n",
    "\n",
    "        safety_settings = [\n",
    "            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        ]\n",
    "\n",
    "        response = gemini_model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                candidate_count=1,\n",
    "                max_output_tokens=completion_tokens,\n",
    "                temperature=temp\n",
    "            ),\n",
    "            safety_settings=safety_settings\n",
    "        )\n",
    "\n",
    "        input_toks = response.usage_metadata.prompt_token_count\n",
    "        output_toks = response.usage_metadata.candidates_token_count\n",
    "        cost_usd = input_toks / 1_000_000 * 1.25 + output_toks / 1_000_000 * 5\n",
    "\n",
    "        # Update costs.json with locking\n",
    "        with lock:\n",
    "            if os.path.exists('gemini_costs.json'):\n",
    "                with open('gemini_costs.json', 'r') as f:\n",
    "                    costs = json.load(f)\n",
    "            else:\n",
    "                costs = {}\n",
    "            costs[model] = costs.get(model, 0) + cost_usd\n",
    "            with open('gemini_costs.json', 'w') as f:\n",
    "                json.dump(costs, f)\n",
    "\n",
    "        inference = response.text.strip() if response.text else None\n",
    "\n",
    "        if inference:\n",
    "            return inference\n",
    "        else:\n",
    "            print('Error: message is empty')\n",
    "            time.sleep(5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Request failed.\")\n",
    "        print(e)\n",
    "        time.sleep(5)\n",
    "\n",
    "    return None\n",
    "\n",
    "# %%\n",
    "# Configuration for OpenAI\n",
    "api_key = \"\"\n",
    "openai_client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "def run_openai_query(prompt, history, completion_tokens, temp, model, openai_client):\n",
    "    response = None\n",
    "    try:\n",
    "        messages = history + [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=temp,\n",
    "            max_tokens=completion_tokens,\n",
    "            messages=messages,\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "            \n",
    "        if content:\n",
    "            return content\n",
    "        else:\n",
    "            print('Error: message is empty')\n",
    "            time.sleep(5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Request failed.\")\n",
    "        print(e)\n",
    "        time.sleep(5)\n",
    "\n",
    "    return None\n",
    "\n",
    "# %%\n",
    "# Function to parse scenes from text\n",
    "def parse_scenes_from_text(text: str):\n",
    "    try:\n",
    "        scene_pattern = re.compile(r'## SCENE \\d+:\\n(.+?)(?=(?:## SCENE \\d+:|$))', re.DOTALL)\n",
    "        scenes = scene_pattern.findall(text)\n",
    "        return [scene.strip() for scene in scenes] if scenes else []\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "# %%\n",
    "# Selection prompt template\n",
    "selection_prompt = \"\"\"\n",
    "[TEXT START]\n",
    "<TEXT>\n",
    "[TEXT END]\n",
    "\n",
    "Your task is to examine the above **public domain** work for evocative, interesting, well-written scenes.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Choose 3 long scenes of approx 1000-1500 words, and output them in their entirety.\n",
    "- You must also repair paragraphs by restoring sentences within a paragraph that are broken by a newline.\n",
    "- Double newline between paragraphs.\n",
    "- Do not include chapter names.\n",
    "\n",
    "Output in this format:\n",
    "\n",
    "## THOUGHT PROCESS:\n",
    "\n",
    "<thought process for the scene selection>\n",
    "\n",
    "## SCENE 1:\n",
    "\n",
    "<the text of approx 1000-1500 words>\n",
    "\n",
    "## SCENE 2:\n",
    "\n",
    "<the text of approx 1000-1500 words>\n",
    "\n",
    "## SCENE 3:\n",
    "\n",
    "<the text of approx 1000-1500 words>\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "Output precisely in this format. Do not add any additional commentary or explanations.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Function to detect file encoding\n",
    "def detect_encoding(file_path: Path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            raw_data = f.read(100000)  # Read first 100KB for detection\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "        confidence = result['confidence']\n",
    "        if encoding:\n",
    "            encoding_lower = encoding.lower()\n",
    "            if encoding_lower in ['ascii', 'charmap']:\n",
    "                return 'latin-1'\n",
    "            if confidence >= 0.5:\n",
    "                return encoding\n",
    "        return 'utf-8'  # Fallback encoding\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting encoding for '{file_path}': {e}. Falling back to 'utf-8'.\")\n",
    "        return 'utf-8'  # Fallback encoding\n",
    "\n",
    "# %%\n",
    "# Worker function to process a single file\n",
    "def process_file(fn, base_path, results_path, selection_prompt):\n",
    "    # Check if file already processed\n",
    "    with lock:\n",
    "        if os.path.exists(results_path):\n",
    "            with open(results_path, 'r') as f:\n",
    "                scenes = json.load(f)\n",
    "        else:\n",
    "            scenes = {}\n",
    "        if fn in scenes:\n",
    "            print(f\"Skipping '{fn}': already processed.\")\n",
    "            return\n",
    "\n",
    "    # Check if file exists\n",
    "    zip_path = os.path.join(base_path, fn)\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"Skipping '{fn}': file does not exist.\")\n",
    "        return\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(tmpdirname)\n",
    "        except zipfile.BadZipFile:\n",
    "            print(f\"Skipping '{zip_path}': Not a valid zip file.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting '{zip_path}': {e}\")\n",
    "            return\n",
    "\n",
    "        extracted_files = list(Path(tmpdirname).rglob(\"*\"))\n",
    "        text_files = [f for f in extracted_files if f.is_file() and f.suffix.lower() in ['.txt', '.md', '.text']]\n",
    "\n",
    "        if len(text_files) != 1:\n",
    "            print(f\"Skipping '{zip_path}': Expected 1 text file, found {len(text_files)}.\")\n",
    "            return\n",
    "\n",
    "        text_file = text_files[0]\n",
    "\n",
    "        # Detect encoding\n",
    "        encoding = detect_encoding(text_file)\n",
    "        try:\n",
    "            with open(text_file, 'r', encoding=encoding, errors='replace') as f:\n",
    "                content = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading '{text_file}': {e}\")\n",
    "            return\n",
    "\n",
    "        if len(content) < 10000:\n",
    "            print(f\"Skipping '{fn}': content too small!\")\n",
    "            return\n",
    "        \n",
    "        if content.find('End of the Project Gutenberg'):\n",
    "            content = content[:content.find('End of the Project Gutenberg')].strip()\n",
    "        else:\n",
    "            print('!! not found')\n",
    "\n",
    "        max_seg_length = 400000\n",
    "        # Split into 4 even segments, ensuring max length\n",
    "        #segment_length = max_seg_length\n",
    "        #segments = [content[i:i+segment_length] for i in range(0, len(content), segment_length)]\n",
    "        #segments = segments[:4]  # Limit to first 4 segments\n",
    "        segments = [content[i:i+len(content)//4][:max_seg_length] for i in range(0, len(content), len(content)//4)]\n",
    "        segments = segments[:4]\n",
    "\n",
    "        # Collect scenes from all segments\n",
    "        all_scenes = []\n",
    "        for i, segment in enumerate(segments):\n",
    "            prompt = selection_prompt\n",
    "            if i == 0:\n",
    "                prompt += \"\\nThe first scene you select should be the very start of the book. The other two can be selected from anywhere.\"\n",
    "\n",
    "            prompt = prompt.replace('<TEXT>', segment)\n",
    "\n",
    "            result = run_gemini_query(prompt, [], 16000, 0, \"gemini-1.5-pro-002\")\n",
    "\n",
    "            #print('-'*10)\n",
    "            #print(result)\n",
    "            #print('-'*10)\n",
    "\n",
    "            if result:\n",
    "                this_scenes = parse_scenes_from_text(result)\n",
    "                print(len(this_scenes))\n",
    "                #if not scenes:\n",
    "                #    print('!!')\n",
    "\n",
    "                all_scenes.extend(this_scenes)\n",
    "            else:\n",
    "                print(f\"Failed to get scenes for '{fn}' segment {i+1}.\")\n",
    "\n",
    "            \n",
    "\n",
    "        # Update scenes.json with locking\n",
    "        with lock:\n",
    "            if os.path.exists(results_path):\n",
    "                with open(results_path, 'r') as f:\n",
    "                    scenes = json.load(f)\n",
    "            else:\n",
    "                scenes = {}\n",
    "            if fn not in scenes:\n",
    "                scenes[fn] = []\n",
    "            scenes[fn].extend(all_scenes)\n",
    "            with open(results_path, 'w') as f:\n",
    "                json.dump(scenes, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# %%\n",
    "# Main function to orchestrate multithreading\n",
    "def main():\n",
    "    #filenames_path = 'data/fiction_book_selections.json'\n",
    "    #filenames_path = 'data/fantasy_book_selections.json'\n",
    "    #filenames_path = 'data/scifi_book_selections.json'\n",
    "    filenames_path = 'data/romance_book_selections.json'\n",
    "    base_path = \"/mnt/i/gutenberg_processed/\"\n",
    "    #results_path = \"scenes.json\"\n",
    "    #results_path = \"scenes_fantasy.json\"\n",
    "    #results_path = \"scenes_scifi.json\"\n",
    "    results_path = \"scenes_romance.json\"\n",
    "    num_threads = 8\n",
    "\n",
    "    # Load filenames\n",
    "    with open(filenames_path, 'r') as f:\n",
    "        filenames = json.load(f)\n",
    "\n",
    "    #print(len(filenames))\n",
    "    \n",
    "    with open('data/fiction_book_selections.json', 'r') as f:\n",
    "        already_selected = json.load(f)\n",
    "\n",
    "    \n",
    "\n",
    "    filenames = [fn for fn in filenames if fn not in already_selected] \n",
    "    #print(len(filenames))\n",
    "\n",
    "    with open('data/scifi_book_selections.json', 'r') as f:\n",
    "        already_selected = json.load(f)\n",
    "\n",
    "    \n",
    "\n",
    "    filenames = [fn for fn in filenames if fn not in already_selected] \n",
    "    #print(len(filenames))\n",
    "\n",
    "    \n",
    "\n",
    "    # Initialize tqdm\n",
    "    progress = tqdm(total=len(filenames), desc=\"Processing files\")\n",
    "\n",
    "    # Define a helper to update tqdm\n",
    "    def update_progress(future):\n",
    "        progress.update(1)\n",
    "        exception = future.exception()\n",
    "        if exception:\n",
    "            print(f\"Error occurred: {exception}\")\n",
    "\n",
    "    # Use ThreadPoolExecutor for multithreading\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = []\n",
    "        for fn in filenames:\n",
    "            future = executor.submit(process_file, fn, base_path, results_path, selection_prompt)\n",
    "            future.add_done_callback(update_progress)\n",
    "            futures.append(future)\n",
    "\n",
    "        # Wait for all futures to complete\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "    progress.close()\n",
    "    print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   2%|▏         | 1/57 [07:17<6:48:38, 437.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   4%|▎         | 2/57 [09:28<3:55:33, 256.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   5%|▌         | 3/57 [10:17<2:25:51, 162.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   7%|▋         | 4/57 [10:48<1:37:25, 110.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   9%|▉         | 5/57 [11:52<1:21:08, 93.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  11%|█         | 6/57 [12:20<1:00:46, 71.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  12%|█▏        | 7/57 [12:40<45:34, 54.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  14%|█▍        | 8/57 [14:31<59:10, 72.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  16%|█▌        | 9/57 [16:42<1:12:43, 90.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  18%|█▊        | 10/57 [17:12<56:17, 71.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  19%|█▉        | 11/57 [20:53<1:30:05, 117.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get scenes for 'Mary_Johnston -- To_Have_and_To_Hold.zip' segment 4.\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  21%|██        | 12/57 [21:49<1:14:05, 98.79s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  23%|██▎       | 13/57 [22:02<53:23, 72.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  25%|██▍       | 14/57 [22:16<39:33, 55.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  26%|██▋       | 15/57 [25:12<1:04:05, 91.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  28%|██▊       | 16/57 [25:17<44:44, 65.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  30%|██▉       | 17/57 [25:38<34:41, 52.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Ellen_Glasgow -- Life_and_Gabriella.zip' segment 1.\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Ellen_Glasgow -- Virginia.zip' segment 1.\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  32%|███▏      | 18/57 [28:44<1:00:06, 92.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Ellen_Glasgow -- Life_and_Gabriella.zip' segment 2.\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Ellen_Glasgow -- The_Romance_of_a_Plain_Man.zip' segment 1.\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  33%|███▎      | 19/57 [31:16<1:09:47, 110.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Ellen_Glasgow -- Virginia.zip' segment 3.\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  35%|███▌      | 20/57 [32:50<1:04:55, 105.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  37%|███▋      | 21/57 [33:40<53:21, 88.92s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  39%|███▊      | 22/57 [33:48<37:38, 64.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  40%|████      | 23/57 [34:05<28:24, 50.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  42%|████▏     | 24/57 [34:52<27:03, 49.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Ellen_Glasgow -- The_Voice_of_the_People.zip' segment 1.\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "3\n",
      "Failed to get scenes for 'Ellen_Glasgow -- The_Romance_of_a_Plain_Man.zip' segment 3.\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  44%|████▍     | 25/57 [38:14<50:42, 95.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Mrs_E_D_E_N_Southworth -- For_Woman's_Love.zip' segment 2.\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  46%|████▌     | 26/57 [38:39<38:21, 74.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get scenes for 'Ellen_Glasgow -- The_Romance_of_a_Plain_Man.zip' segment 4.\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  47%|████▋     | 27/57 [41:43<53:36, 107.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  49%|████▉     | 28/57 [42:28<42:45, 88.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get scenes for 'Ellen_Glasgow -- The_Voice_of_the_People.zip' segment 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  51%|█████     | 29/57 [42:38<30:12, 64.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  53%|█████▎    | 30/57 [42:59<23:15, 51.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  54%|█████▍    | 31/57 [43:23<18:51, 43.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  56%|█████▌    | 32/57 [46:13<33:56, 81.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  58%|█████▊    | 33/57 [48:08<36:35, 91.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  60%|█████▉    | 34/57 [50:16<39:16, 102.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  61%|██████▏   | 35/57 [51:42<35:46, 97.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  63%|██████▎   | 36/57 [51:45<24:13, 69.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  65%|██████▍   | 37/57 [52:47<22:18, 66.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  67%|██████▋   | 38/57 [53:21<18:02, 56.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  68%|██████▊   | 39/57 [53:46<14:15, 47.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Gertrude_Atherton -- Senator_North.zip' segment 1.\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  70%|███████   | 40/57 [57:06<26:26, 93.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Failed to get scenes for 'Gertrude_Atherton -- Senator_North.zip' segment 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  72%|███████▏  | 41/57 [57:39<20:04, 75.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  74%|███████▎  | 42/57 [58:38<17:32, 70.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 7.\n",
      "Failed to get scenes for 'Gertrude_Atherton -- Senator_North.zip' segment 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  75%|███████▌  | 43/57 [59:45<16:08, 69.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  77%|███████▋  | 44/57 [1:01:10<16:04, 74.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  79%|███████▉  | 45/57 [1:01:28<11:25, 57.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  81%|████████  | 46/57 [1:03:32<14:10, 77.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  82%|████████▏ | 47/57 [1:03:38<09:19, 55.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  84%|████████▍ | 48/57 [1:06:21<13:12, 88.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  86%|████████▌ | 49/57 [1:06:37<08:50, 66.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  88%|████████▊ | 50/57 [1:09:13<10:52, 93.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "Request failed.\n",
      "Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
      "This appears to be caused by a blocked prompt, see `response.prompt_feedback`: block_reason: PROHIBITED_CONTENT\n",
      "\n",
      "Failed to get scenes for 'Sarah_Orne_Jewett -- Betty_Leicester.zip' segment 2.\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  89%|████████▉ | 51/57 [1:11:19<10:19, 103.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  91%|█████████ | 52/57 [1:11:20<06:01, 72.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  93%|█████████▎| 53/57 [1:12:30<04:47, 71.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  95%|█████████▍| 54/57 [1:14:27<04:15, 85.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  96%|█████████▋| 55/57 [1:15:37<02:41, 80.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  98%|█████████▊| 56/57 [1:15:41<00:57, 57.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 57/57 [1:16:55<00:00, 80.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
